<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>KAO: Kernel-Adaptive Optimization in Diffusion</title>
  <link rel="icon" href="sat.png" type="image/png" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet" />
  <style>
    body {
      font-family: 'Inter', sans-serif;
      margin: 0;
      padding: 0;
      background-color: #fff;
      color: #111;
      line-height: 1.7;
    }

    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 50px 20px;
    }

    h1, h2, h3 {
      font-weight: 800;
      color: #111;
    }

    a {
      color: #000;
      text-decoration: underline;
    }

    .author {
      font-size: 1.1rem;
      text-align: center;
      margin-top: -20px;
      color: #333;
    }

    .ieee-banner {
      text-align: center;
      background: #f4f4f4;
      padding: 15px;
      border-left: 5px solid #0073e6;
      margin: 40px 0;
      font-size: 1rem;
      font-weight: 600;
    }

    .teaser {
      width: 100%;
      margin: 40px 0;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .section {
      margin-top: 60px;
    }

    .fig-img {
      width: 100%;
      margin: 30px 0;
      border: 1px solid #ccc;
      border-radius: 6px;
    }

    .caption {
      font-size: 0.95rem;
      color: #666;
      margin-top: -20px;
      margin-bottom: 40px;
      text-align: center;
    }

    .btn {
      display: inline-block;
      margin: 10px 10px 30px 0;
      padding: 10px 20px;
      background: #000;
      color: #fff;
      border-radius: 4px;
      text-decoration: none;
      font-weight: 600;
      border: 1px solid #000;
      transition: 0.3s;
    }

    .btn:hover {
      background: #fff;
      color: #000;
    }

    footer {
      margin-top: 100px;
      font-size: 0.9rem;
      color: #999;
      text-align: center;
      padding-bottom: 40px;
    }

    code {
      background: #f5f5f5;
      padding: 2px 5px;
      border-radius: 4px;
      font-family: monospace;
    }

    pre {
      background: #f5f5f5;
      padding: 15px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.9rem;
    }

    mjx-container {
      overflow-x: auto;
      overflow-y: hidden;
    }

  </style>
</head>

<script>
  window.MathJax = {
    tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
    svg: { fontCache: 'global' }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>

<body>
  <div class="container">
    <h1 style="text-align:center;">KAO: Kernel-Adaptive Optimization</h1>
    <p class="author"><strong>Teerapong Panboonyuen</strong><br>Chulalongkorn University</p>

  <div class="ieee-banner">
    üéâ Accepted to <strong>IEEE Transactions on Geoscience and Remote Sensing<br>(TGRS, Impact Factor: 8.6)</strong>
  </div>

    <img src="results/re_show_01.png" alt="Teaser" class="teaser">

    <div style="text-align:center;">
      <a class="btn" href="https://kaopanboonyuen.github.io/KAO/">üåê Project Page</a>
      <a class="btn" href="https://doi.org/10.1109/TGRS.2025.3621738" target="_blank">üìÑ PDF (Coming Soon)</a>
      <a class="btn" href="https://github.com/kaopanboonyuen/KAO" target="_blank">üíª Code (Coming Soon)</a>
    </div>

    <div class="section">
      <h2>Abstract</h2>
      <p>
        Satellite image inpainting is critical in remote sensing applications. We propose <strong>KAO</strong>, a diffusion-based framework enhanced with <strong>Kernel-Adaptive Optimization</strong> and <strong>Token Pyramid Transformer (TPT)</strong>, enabling dynamic kernel modulation in latent space. KAO delivers high-fidelity, structure-aware reconstructions, outperforming existing models like Stable Diffusion, RePaint, and SatDiff across VHR datasets.
      </p>
    </div>

    <div class="section">
      <h2>Results Overview</h2>

      <img src="results/re_show_01.png" class="fig-img">
      <div class="caption">
        Qualitative comparison with 7 models. KAO shows superior restoration across various occlusion patterns.
      </div>

      <img src="results/re_show_02.png" class="fig-img">
      <div class="caption">
        Detailed sample comparisons. KAO excels in reconstructing linear features and textures in urban scenes.
      </div>
<div class="section">
  <h2>Approach</h2>
  <p>
    This section introduces the mathematical foundation of <strong>Kernel-Adaptive Optimization (KAO)</strong> and how it enhances diffusion-based inpainting for satellite imagery. Our method modifies the training objective of diffusion models to be <em>spatially adaptive</em>, allowing the model to focus more on complex or ambiguous regions ‚Äî a crucial property for high-fidelity satellite image restoration.
  </p>

  <h3>Diffusion Process</h3>
  <p>
    Diffusion models are trained by gradually corrupting an image \( x_0 \) into noise through a forward stochastic process:
  </p>
  <div class="math-display">
    \[
    q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
    \]
  </div>
  <p>
    Here, \( \alpha_t \) controls the noise schedule at time step \( t \). Over many steps, the image becomes pure noise. The model learns to reverse this corruption ‚Äî i.e., denoise:
  </p>
  <div class="math-display">
    \[
    p(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t), \Sigma_\theta(x_t))
    \]
  </div>
  <p>
    The goal is to predict a clean sample \( x_{t-1} \) given a noisy one \( x_t \), using learned parameters \( \theta \).
  </p>

  <h3>Optimization Objective</h3>
  <p>
    Traditional training minimizes the Kullback-Leibler divergence between the true reverse process and the model's approximation:
  </p>
  <div class="math-display">
    \[
    \arg \min_{\theta} \mathbb{E}_{t} \left[ D_{KL}(q(x_{t-1}|x_t, x_0) \parallel p_{\theta}(x_{t-1}|x_t)) \right]
    \]
  </div>
  <p>
    This objective treats all pixels and regions equally. But in satellite images, some areas (e.g., occlusions or fine-grained structures) are harder to reconstruct and more important for downstream analysis.
  </p>

  <h3>Kernel-Adaptive Optimization (KAO)</h3>
  <p>
    To address this, we introduce <strong>Kernel-Adaptive Optimization</strong>, a spatially-aware training scheme. KAO modifies the loss to weight each training example based on the difference between noisy and denoised states:
  </p>
  <div class="math-display">
    \[
    \theta^* = \arg\min_\theta \mathbb{E}_{t} \left[ D_{KL}(q(x_{t-1}|x_t, x_0) \parallel p_\theta(x_{t-1} | x_t)) \cdot K(x_t, x_{t-1}) \right]
    \]
  </div>
  <p>
    The kernel \( K(x_t, x_{t-1}) \) acts as an adaptive weight, emphasizing regions with greater uncertainty or semantic change:
  </p>
  <div class="math-display">
    \[
    K(x_t, x_{t-1}) = \exp\left(-\frac{\|x_t - x_{t-1}\|^2}{2\sigma^2}\right)
    \]
  </div>
  <p>
    This formulation encourages the model to learn more from areas where its current predictions deviate most from the target. Intuitively, this means KAO focuses learning capacity on <em>harder regions</em> ‚Äî such as occluded structures or fine textures ‚Äî resulting in better inpainting quality, especially in geospatial contexts.
  </p>

  <h3>SDE Formulation</h3>
  <p>
    In continuous time, the forward diffusion can be described by a stochastic differential equation (SDE):
  </p>
  <div class="math-display">
    \[
    dX_t = f(X_t, t) \, dt + g(t) \, dW_t
    \]
  </div>
  <p>
    And the learned reverse-time process becomes:
  </p>
  <div class="math-display">
    \[
    dX_t = \left[f(X_t, t) - g(t)^2 s_\theta(X_t, t)\right] \, dt + g(t) \, d\bar{W}_t
    \]
  </div>
  <p>
    This SDE-based view supports advanced sampling strategies and allows KAO to extend to continuous-time score-based generative models.
  </p>

  <h3>Token-Level Conditioning</h3>
  <p>
    KAO also supports flexible conditioning in latent space. During inference, we blend representations from both the inferred and conditioning paths:
  </p>
  <div class="math-display">
    \[
    h^* = h^{infr} \odot (1 - D(m)) + h^{cond} \odot D(m)
    \]
  </div>
  <p>
    where \( D(m) \) is a learned decoder map derived from the binary mask \( m \). Finally, the denoised outputs are blended similarly:
  </p>
  <div class="math-display">
    \[
    x_{t-1} = x_{t-1}^{infr} \odot (1 - m) + x_{t-1}^{cond} \odot m
    \]
  </div>
  <p>
    This ensures spatially-aware reconstruction: occluded regions follow the conditional guidance, while unoccluded areas retain the model‚Äôs generative diversity.
  </p>
</div>



<h3>How to Read the Following Results</h3>
<p>
  Each scene below presents a qualitative comparison of inpainting performance across seven models.
  From left to right, the columns show:
</p>
<ul>
  <li>(1) The occluded input</li>
  <li>(2) The ground truth image</li>
  <li>(3) Stable Diffusion [25]</li>
  <li>(4) RePaint [16]</li>
  <li>(5) SatDiff [1]</li>
  <li>(6) DPS [26]</li>
  <li>(7) PSLD [27]</li>
  <li>(8) <strong>Our method ‚Äì KAO</strong></li>
</ul>
<p>
  Each row corresponds to a different scene type‚Äîranging from urban to agricultural landscapes and cloud-covered areas.
  Compare across columns to evaluate each model‚Äôs ability to restore structural details and textures.
  <strong>KAO</strong> consistently produces high-fidelity outputs that preserve spatial layout, align with real-world features,
  and outperform others in restoring occluded regions.
</p>


      <!-- Loop over all re_all_* -->
      <img src="results/re_all_01.png" class="fig-img">
      <div class="caption">Scene 1 ‚Äì Urban satellite reconstruction comparison.</div>

      <img src="results/re_all_02.png" class="fig-img">
      <div class="caption">Scene 2 ‚Äì Agricultural patterns, occlusion restoration.</div>

      <img src="results/re_all_03.png" class="fig-img">
      <div class="caption">Scene 3 ‚Äì Reconstruction under heavy cloud occlusions.</div>

      <img src="results/re_all_04.png" class="fig-img">
      <div class="caption">Scene 4 ‚Äì Comparison on semi-urban environment.</div>

      <img src="results/re_all_05.png" class="fig-img">
      <div class="caption">Scene 5 ‚Äì Multi-resolution image restoration results.</div>

      <img src="results/re_all_06.png" class="fig-img">
      <div class="caption">Scene 6 ‚Äì Zoomed-in structural fidelity of KAO.</div>
    </div>

    <div class="section">
      <h2>BibTeX Citation</h2>
      <pre><code>@article{panboonyuen2025kao,
      author    = {Teerapong Panboonyuen},
      title     = {KAO: Kernel-Adaptive Optimization in Diffusion for Satellite Image},
      journal   = {IEEE Transactions on Geoscience and Remote Sensing},
      year      = {2025},
      doi       = {10.1109/TGRS.2025.3621738},
      note      = {Manuscript No. TGRS-2025-06970},
      publisher = {IEEE}
    }</code></pre>
    </div>

    <footer>
      ¬© 2025 Teerapong Panboonyuen ¬∑ IEEE TGRS ¬∑ Project page inspired by <a href="https://weirdlabuw.github.io/vpl/">VPL</a>
    </footer>
  </div>
</body>
</html>
